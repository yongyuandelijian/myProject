# 功能：获取文档固定文本部分，按照章节情况将内容保存到一个字典中
# 这一块内容其实适合存储到数据库中，这样结构就会特别清晰,也会便于维护,另外就是目前每一个变量都分的很清，其实没有必要。可优化
# date:20200723
# author:aaa

class get_ybwb(object):
    '''获取文档固定文本部分，按照章节情况将内容保存到一个字典中'''

    def hqnr(self):
        '''获取文档固定文本部分，按照章节情况将内容保存到一个字典中'''
        # 第一章两级标题加内容
        jb1_1 = "第1章\t概述"
        jb2_11 = "1.1\t编写目的"
        nr01 = "总局大数据云平台建设需要将各个涉税相关系统及外部交换等系统数据集成到云平台中，大部分数据是按一定频率通过部署链路及任务进行周期性采集，针对各采集链路及调度任务需要进行日常性保障监控，对于整体数据的集成情况及各类异常问题需要进行记录统计并总结，逐步改善云平台数据集成的完整性、准确性及一致性。本文档就整体数据集成情况及每月在集成过程中遇到的各类异常问题进行相应的汇总说明，以此来呈现给各方以更好的了解数据集成及保障情况。"
        jb2_11 = {jb2_11: [nr01]}
        jb2_12 = "1.2\t阅读对象"
        nr01 = "总局大数据云平台项目组甲方及乙方管理人员。"
        jb2_12 = {jb2_12: [nr01]}
        jb2_13 = "1.3\t相关术语"
        nr01 = "1、项目空间：是阿里云大数据集成服务平台最基本的组织对象，是用户管理表（Table） 、资源（Resource） 、自定义函数（UDF） 、节点（Node） 、权限等的基本单元。"
        nr02 = "2、Data IDE：数据开发套件（DataIDE，Data Integrated Development Environment）是一种简单高效，图形化页面化构建和实现算法逻辑，实施数据处理的调试和定期运维的集成环境。"
        nr03 = "3、OGG：Oracle Golden Gate 软件的简称，是一种基于日志的结构化数据复制备份软件，它通过解析源数据库在线日志或归档日志获得数据的增量变化。"
        nr04 = "4、ODPS：大数据计算服务简称，是一种快速、完全托管的 TB/PB 级数据仓库解决方案。"
        nr05 = "5、CDP：批量数据同步组件简称，是一个稳定高效、弹性伸缩的数据集成平台，为阿里云大数据计算引擎(包括 ODPS、ADS 、StreamCompute)提供离线(批量)、实时(流式)的数据进出通道。"
        nr06 = "6、DataX：是一个在异构的数据库/文件系统之间高速交换数据的工具，实现了在任意的数据处理系统(RDBMS/Hdfs/Local filesystem)之间的数据交换。"
        nr07 = "7、DataHub服务：阿里云提供的流式数据处理(Streaming  Data)服务，它提供流式数据的发布 (Publish)和订阅 (Subscribe)的功能，与阿里云流计算引擎 StreamCompute 无缝连接，用户可以轻松使用SQL 进行流数据分析。"
        nr08 = "8、StreamCompute：流计算简称，是阿里云提供的流计算引擎，提供使用类 SQL的语言来进行流式计算。DataHub 服务和 StreamCompute 无缝结合，可以作为 StreamCompute的数据源和输出源。"
        nr09 = "9、OSS：对象存储（Object Storage Service）简称，提供基于网络的数据存取服务。通过网络随时存储和调用包括文本、图片、音频、和视频等在内的各种结构化或非结构化数据文件"
        nr10 = "10、离线数据：存储在ODPS中的数据。"
        nr11 = "11、在线数据：存储在RDS、DRDS、ADS、OTS、OSS中的数据。"
        jb2_13 = {jb2_13: [nr01, nr02, nr03, nr04, nr05, nr06, nr07, nr08, nr09, nr10, nr11]}
        # jb1_1 = {jb1_1:[jb2_11,jb2_12,jb2_13]}

        # 第二章四级标题外加内容
        jb1_2 = "第2章\t数据集成情况说明"
        jb2_21 = "2.1\t链路介绍"
        nr2101 = "目前总局云平台数据采集链路及分层架构，基于目前总局、省级单位相关税收业务数据、外部交换数据、出口退税、电子底账和互联网采集等数据的分布特性，云平台目前共有13条数据集成链路，根据不同的数据来源，我们采用相对应的技术工具，将不同位置不同业务的数据源数据首先采集至云平台各项目独立存储区即镜像层，再按需同步至税务总局基础层，个别临时提供的数据直接集成到税务总局基础层，最终实现云平台基础数据层数据的采集。"
        nr2102 = "如上图所示：各省局单位在云平台有自己对应的镜像/临时层项目空间，总局数据大部分在统一的总局镜像层项目空间，其它各专项需求数据也有自己对应单独镜像层项目空间，每部分数据原则上首先是进入云平台镜像层，再按需进入下游。下面分别说明各链路情况。"
        nr21 = [nr2101, nr2102]

        jb3_2101 = "2.1.1\t省级单位数据源（36家）集成链路"
        jb4_210101 = "2.1.1.1\t链路1：金三核心征管、个税系统及电子税务局数据集成"
        nr01 = "主要包含了核心征管系统的申报、征收、登记、发票、纳评、票证、认定、税服、优惠、证明、代码参数等业务域数据，旧个税系统的登记、申请、认定、征收、代码等业务域数据，新出口退税系统（已切换6家单位）的备案、审核、风险、评估、申报、证明、代码参数等业务域数据；省局社保费子系统（已试点6家单位）的社保费征收、管理、申报等数据； 好差评系统的评价意见等数据。此链路中集成的数据均是从源端将生产库数据同步到各地核心征管分发库中，云平台再通过在每个单位分发库部署的OGG工具以增量文件形式将数据文件获取到云平台服务器，每日再通过配置云平台调度任务将日志文件数据加载到ODPS对应表中，每日增量数据先进入云平台各单位临时层，再merge到云平台基础层供下游使用。"
        jb4_210101 = {jb4_210101: [nr01]}
        jb3_2101 = {jb3_2101: [jb4_210101]}

        jb3_2102 = "2.1.2\t总局数据源集成链路"
        jb4_210201 = "2.1.2.1\t链路2：总局决策1包数据集成"
        nr01 = "主要包括电子底账的普通发票，专票，电子发票，卷式发票；货运普通发票，专票，电子发票，卷式发票；发票认证信息；机动车发票，通行费发票，电子专票，二手车发票等发票相关数据；异地协作平台的协查、核查、函调及异常扣税数据；纳服司的申报信息；财行减税降费数据；营改增分析数据；深化增值税改革效应分析数据；决一大屏展示数据。此此链路中电子底账数据是由长软每日以增量方式从省局底账库获取数据并推送至总局1包，其它数据生产于一包库，云平台通过配置调度任务每日进行增量或全量方式采集集成到云平台国税总局镜像层，再merge到基础层供下游使用。"
        jb4_210201 = {jb4_210201: [nr01]}
        jb4_210202 = "2.1.2.2\t链路3：总局决策2包数据集成"
        nr01 = "主要包括风险管理系统、稽查双随机案源管理系统、稽查指挥系统、纳税信用管理系统、企税数据质量监控，涉税信用管理的风险应对、风险过程，风险情报、风险信用、任务下发、风险识别、风险反馈、信用评级等数据，此部分数据每天通过云平台配置的调度任务按天全量抽取，先进入云平台国税总局镜像层，再同步到基础层供下游加工使用。"
        jb4_210202 = {jb4_210202: [nr01]}
        jb4_210203 = "2.1.2.3\t链路4：总局外部交换数据集成"
        nr01 = "主要包括海关的报送单数据、电子账册、完税证等业务域数据；工商的工商登记信息、投资方信息数据；发改委的红黑名单、失信企业名单等数据；银保监会的商业保障、养老保障数据；人民银行的跨境收入信息、境外申报备案等数据；外汇局的非居民企业征税、出口退税企业管理信息等数据；代码中心的对账信息；中机中心的车辆合格证信息、免税图册、合格证电子信息等数据；最高法的失信被执行人信息；公共资源交易中心的交易公告数据；医保局的大病医疗数据。此链路数据集成全部是增量对账方式按天通过调度任务集成，按需同步到基础层供下游使用。"
        jb4_210203 = {jb4_210203: [nr01]}
        jb4_210204 = "2.1.2.4\t链路5：电子底账发票2.0系统数据集成"
        nr01 = "此部分数据来自总局电子底账系统，主要涉及增值税发票，普通发票，电子发票等业务域数据，共50张表，其中24张是t+1（天）时效集成，26张是t+0.5（小时）时效集成。云平台采集后将增量推送到快速加工区，全量经过中间层进行标准化之后，供服务组以及模型层等上游按照业务进行加工统计。"
        jb4_210204 = {jb4_210204: [nr01]}
        jb4_210205 = "2.1.2.5\t链路6：出口退税数据集成"
        nr01 = "主要是出口退税审核系统的认定、免抵退、退税申报、退税审批审核、外贸、加工贸易、业务流程、代码等数据，目前由大连龙图每周六将各省数据抽取到总局出口退税库，云平台每周一通过调度任务全量从总局出口退税库进行抽取，抽取先进行镜像层，再同步到基础层供下游使用。"
        jb4_210205 = {jb4_210205: [nr01]}
        jb4_210206 = "2.1.2.6\t链路7：总局其它应用系统数据集成"
        nr01 = "主要包括分险分析应对指挥平台的案例管理数据、风险过程数据、风险监控、风险应对等数据；总局实名办税系统的实名办税身份信息、风险纳税人名单等数据；总局督查内审内控平台的执法风险监控指标数据；总局12366纳服热线平台的来电信息，热线咨询记录等数据；总局国际税收管理平台的反避税数据；总局增值税发票风险管理系统的风险特征、异常发票等数据及总局大企业司账套数据。此部分数据除内控平台数据是按月全量集成外，其它数据均是按天增量采集，先进入云平台镜像层，再同步至基础层供下游使用。"
        jb4_210206 = {jb4_210206: [nr01]}
        jb4_210207 = "2.1.2.7\t链路8：互联网爬取数据集成"
        nr01 = "以总局为节点采集政府公开公示、企业官网以及财经新闻门户、东方财富网股东信息等互联网信息，集成后进行结构化再集成到云平台镜像层，按需同步到基础层供下游使用，此类数据为按需集成。"
        jb4_210207 = {jb4_210207: [nr01]}
        jb4_210208 = "2.1.2.8\t链路9：外部临时导出数据集成"
        nr01 = "针对一些临时需求从外部其它系统临时导出的相关数据进行云平台导入集成，目前已经集成的有公安自然人身份信息数据、宁波市各部门个税测算数据、海关注册企业信息(数据由海关总署风险管理司提供),最高法裁决文书、收规司社保数据、大企业及千户集团数据、所得税司商品清单,稽查局违法案件数据、纳服司涉税举报数据、税务审计软件数据、收规司企业出口情况数据、湖南工商比对核实数据、网信办复工复产数据、所得税司高新企业名单等，此部分数据经常以文件形式提供，单次按需集成，所有数据均直接进入云平台基础层，供下游直接加工使用。"
        jb4_210208 = {jb4_210208: [nr01]}
        jb4_210209 = "2.1.2.9\t链路10：老核心征管系统历史数据集成 "
        nr01 = "针对总局电税中心留存的核心管理历史数据（CTAIS1.1、2.0）进行采集集成，此部分数据也是独立需求，在云平台做为独立项目进行数据分析使用，因此数据存放于自己独立镜像层下进行加工分析使用,该项需求由征科司提出。"
        jb4_210209 = {jb4_210209: [nr01]}
        jb4_210210 = "2.1.2.10\t链路11：电子商务数据集成"
        nr01 = "针对罗格公司的电子商务相关各类数据进行采集并在云平台进行分析利用，此部分数据也是作为一个专项需求进行使用，因此数据存放于云平台独立镜像层，在镜像层进行整合后按需同步到国税总局基础层与税务数据综合起来使用。"
        jb4_210210 = {jb4_210210: [nr01]}
        jb4_210211 = "2.1.2.11\t链路12：所得税汇算清缴系统数据集成"
        nr01 = "针对总局所得税司所得税汇算清缴系统，涉及两部分数据，一个是所得税汇总纳税相关数据，一个是所得税汇算清缴相关数据进行采集集成，此部分数据是也作为独立需求进行分析使用，因此在云平台存于自己单独的镜像层下，按需分析利用。"
        jb4_210211 = {jb4_210211: [nr01]}
        jb4_210212 = "2.1.2.12\t链路13：自然人电子税务局系统数据集成"
        nr01 = "此部分数据来自总局个税管理系统，主要涉及个税申报、征收、登记、认定及代码等业务域数据，目前均按天抽取集成，按需从ITS系统采集，由于此部分数据安全保密要求较高，进入云平台后配置单独基础层项目空间存储，与公共基础层分开独立开发使用。"
        nr02 = "以上为云平台数据采集链路介绍，云平台将数据采集上来后总体原则是按需同步到基础层，再将基础层的数据加工到中间层，模型层利用中间层加工的结果进行数据模型设计分析。"
        jb4_210212 = {jb4_210212: [nr01,nr02]}
        jb3_2102 = {
            jb3_2102: [jb4_210201, jb4_210202, jb4_210203, jb4_210204, jb4_210205, jb4_210206, jb4_210207, jb4_210208,
                       jb4_210209, jb4_210210, jb4_210211,jb4_210212]}
        jb2_21 = {jb2_21: [jb3_2101, jb3_2102]}

        jb2_22 = "2.2\t数据集成概述"
        nr01 = ""
        nr02 = "1、云平台现已集成的数据"
        nr03 = "税务内部系统数据包含核心征管，个税，出口退税，发票电子底账，电子税务局数据，老征管库历史数据，所得税汇算清缴数据，所得税汇总纳税数据，自然人电子税务局数据，风险管理系统数据，增值税风险发票监控数据，协同办公平台异常抵扣数据，决策二包信用评级数据，决策二包风险信用数据，决策二包风险情报数据，决策一包大屏展示数据，决策一包财行减税降费数据，决策一包营改增分析数据，决策一包纳服司申报信息。"
        nr04 = "外部交换数据包含海关，工商，发改委，银保监会，人民银行，外汇局，代码中心，中机中心，建行，最高法，公共资源交易平台数据。"
        nr05 = "互联网数据包含互联网爬取东方财富网等公开网站数据。"
        nr06 = "临时外部导入包含公安自然人身份信息数据，宁波市各部门个税测算数据，风险司海关注册企业信息，最高法裁决文书，收规司社保数据，大企业及千户集团数据，所得税司商品清单，稽查局违法案件数据，纳服司涉税举报数据，税务审计软件数据，收规司企业出口情况数据，大企业司账套数据，电子商务数据，其它临时导入，湖南工商比对核实数据。"
        nr07 = "2、云平台向外部推送及同步的数据有：总局统一工作平台数据，发改委数据推送数据，外汇局数据推送数据，海关全票面数据推送数据，千万人数据同步数据，稽查选案数据同步数据，电商数据同步数据。以上推送同步指的是向云平台以外，如总局决策一包、总局外部交换等系统推送。"
        nr08 = "3、目前数据抽取统一采用数据交换工具DataX将数据按频度（日/月）、增/全量方式抽取到云平台镜像层，再根据下游应用需求集成到基础层。"
        nr09 = "4、核心征管及个税所有表目前采用增量文件的方式从分发库按日进行采集集成，最终合并到基础层。"
        nr10 = "5、增量方式抽取的表先将数据抽取到临时层，再与上一天镜像层的全量进行合并成当天全量到镜像层，再按需同步到基础层供下游使用。"
        nr11 = "6、 核心征管、个税系统、发票底帐，外部交换系统、风险管理系统的表每天0点开始将T-1日数据抽取到镜像层；风险过程、出口退税数据每月10号将上个月数据抽取到镜像层；决策二包信用评级数据每周一全量抽取集成到基础层。"
        nr12 = "7、互联网、风险过程、千户集团、电子商务和决一营改增分析这五部分数据根据需求按次导入；老的征管历史数据、所得税汇算清缴数据、所得税汇总纳税数据、收规社保数据、宁波各部门个税测算数据、公安自然人身份信息数据及风险司海关注册企业信息数据是单次集成到云平台，以后按需再集成。"
        nr13 = "8、云平台的数据采用切片方式进行存储，每个切片都是一个系统的全量数据。镜像层采用一级分区，其中核心征管、个税系统、发票底账、外部交换均采用日分区，出口退税、纳税信用评级数据采用月分区；基础层采用两级分区，除了日/月分区外还有数据所属地区分区。"
        nr14 = "9、云平台镜像和基础层数据由38个项目组成，分别是36家省级镜像层、1家总局镜像层、1家总局基础层，其中镜像层数据保持贴源，设计基础层的目的是用来标准化清洗数据。"
        jb2_22 = {jb2_22: [nr01, nr02, nr03, nr04, nr05, nr06, nr07, nr08, nr09, nr10, nr11, nr12, nr13, nr14]}

        jb2_23 = "2.3\t运维监控说明"
        nr01 = "源端链路包括省局数据源跟总局数据源链路两部分。总局主要是出口退税、电子底账、外部交换、总局决策一包、二包等数据源，目前总局数据源由于集成的数据表相对于省局比较少，并且总局数据源由各厂商驻场运维，一旦接入云平台数据集成链路，源端数据链路运行会优先及时保障，相对稳定，极少出现异常情况，因此总局数据源链路运行情况主要是人工进行日常性监控，目前无相关自动化工具辅助。省局主要是各单位分发库数据源，由于涉及单位多，同步表数量大，是比较核心重要的链路，针对各单位分发库运行情况，我们在云平台端开发了OGG进程运行监控工具辅助进行源端链路监控。下面重点说明省局数据源链路运行的监控情况："
        nr02 = "目前国地税合并后全国共有36个分发库，分发库全部部署在各地方单位。在整个数据集成链路中，分发库相当于是云平台的源端，各省数据通过前台汇总至核心征管库后，通过OGG生成同步至分发库；在分发库服务器端部署针对云平台集成相关的OGG工具及数据打包传输工具，分钟级执行，生成增量数据文件，云平台按日获取增量数据文件进行集成。"
        jb2_23 = {jb2_23: [nr01, nr02]}
        # jb1_2={jb1_2:[jb2_21,jb2_22,jb2_23]}

        # 第三章3级标题外加内容
        jb1_3 = "第3章\t集成运维监控情况"

        jb2_31 = "3.1\t源端链路监控"
        jb3_3101 = "3.1.1\t分发库运行情况"
        nr01 = "分发库运行情况通过OGG链路监控工具每天对全国36家单位分发库OGG链路运行巡检，对于各进程运行情况进行实时监控。本月每日运维监控各单位分发库链路或OGG进程异常情况统计如下："
        jb3_3101 = {jb3_3101: [nr01]}
        jb3_3102 = "3.1.2\t分发库异常分析"
        nr01 = "针对各单位异常情况进行了跟踪分析，具体如下:"
        jb3_3102 = {jb3_3102: [nr01]}
        jb3_3103 = "3.1.3\t分发库异常应对策略"
        nr01 = "针对分发库各类原因导致的进程异常问题，可采取以下办法应对："
        nr02 = "1、人为导致的未刷新定义文件处理如下："
        nr03 = "停止复制进程，开始执行ggsrun.sh脚本实现定义文件刷新；执行成功后重启相关的ogg进程即可。"
        jb3_3103 = {jb3_3103: [nr01, nr02, nr03]}
        jb2_31 = {jb2_31: [jb3_3101, jb3_3102, jb3_3103]}

        jb2_32 = "3.2\t云平台集成任务监控"
        jb3_3201 = "3.2.1\t集成任务运行情况"
        nr01 = "本月云平台集成任务运行相对平稳良好。"
        jb3_3201 = {jb3_3201: [nr01]}
        jb3_3202 = "3.2.2\t运行失败任务分析"
        nr01 = "从运维监控到的失败任务暴露出的问题来看归纳统计如下："
        jb3_3202 = {jb3_3202: [nr01]}
        jb3_3203 = "3.2.3\t失败任务应对策略"
        jb3_3203 = {jb3_3203: []}
        jb3_3204 = "3.2.4\t数据集成一致性监控处理情况"
        nr01 = "目前云平台数据集成基本都采用datax工具进行任务自动集成，除了核心征管及个税系统数据采用增量文件加载到云平台集成以外，其它系统数据均是通过jdbc直接从源端库抽取到云平台的，全量抽取的这部分数据一致性未存在异常问题，增量抽取的由于表数量较少，数据使用频率不是很高，一般是定期抽样进行差异比对。核心征管与个税数据由于抽取的表数量比较多，且全部是增量抽取，数据使用比较广泛，因此这部分数据一致性比对是日常运维工作当中的重点，增量抽取过程相对复杂，在数据从源端库到云平台同步时存在很多不可控因素，比如源端库数据版本升级不规范等，端与端之间网络不稳定等等，难免导致同步到目标端的数据与源端数据存在一定的不一致性，针对这种不一致性我们采取数据量的比对措施进行验证，以此来保障源库与目标库数据量一致，确保数据在集成过程当中没有丢失。"
        nr02 = "Excel备注说明：\n\t分发库——同步任务启动时分发库此表数据量；\n\t基础层——同步任务结果后基础层此表当天分区数据量\n\t差异——分发库数据量与当天分区基础层数据量的差,即：差异=分发库-基础层\n\t差异率——分发库数据量与当天分区基础层数据量的差与分发库数据量的比，即：差异率=（分发库-基础层）/分发库*100%"
        nr03 = "由此数据量比对结果可看出，数据同步基本稳定，无差异较大情况，由于统计分发库数据量的任务启动时间为每日零点启动，但是任务需要运行10分钟左右（个别单位由于资源问题运行的时间会更长），所以导致统计到的分发库的数据量比实际当天的数据量要多一些，这种情况会通过和第二天的增量进行比较来排除出去，剩下的数据存在差异的表会通过全量初始化的方式来保障数据的完整性。云平台每日对各单位各表数据量比对有所监控，差异率在0.01%（含）及以上的我们当天将会对此表进行全量初始化来补全数据。此次比对结果中是空值的是因为该单位统计该表的数据量的任务卡死，导致获取不到该表数据量，所以该单位分发库数据量值为空，这种表无法进行后续的数据比对，是通过比对云平台中该表的数据趋势来判断该表是否需要处理。"
        jb3_3204 = {jb3_3204: [nr01, nr02, nr03]}
        jb3_3205 = "3.2.5\t源端数据更新情况"
        nr01 = "备注说明：云平台数据未更新的表在源端数据库中无数据变化。"
        jb3_3205 = {jb3_3205: [nr01]}
        jb2_32 = {jb2_32: [jb3_3201, jb3_3202, jb3_3203, jb3_3204, jb3_3205]}
        # jb1_3={jb1_3:[jb2_31,jb2_32]}

        # 第四章 两级标题
        jb1_4 = "第4章\t总结与建议"
        jb2_41 = "4.1\t源端"
        nr01 = "基于上述分析，源端分发库存在的问题有分发库密码过期导致的异常，分发库运维人员操作不规范导致的集成问题，OGG进程异常问题等。"
        nr02 = "对于上述问题的建议解决方案有以下三点："
        nr03 = "（1）各地分发库关于数据集成相关的用户密码或者当地安全策略如有变动，需第一时间告知云平台。"
        nr04 = "（2）各单位加强运维管理，对OGG相关的问题处理严格按照运维规范进行处理并保存自己的操作记录，避免出现不必要的错误。"
        nr05 = "（3）各地如存在非常规操作，需事先通知云平台工作人员，以便云平台对任务进行处理。例如全表的全量初始化操作，对云平台增量任务的压力较大，很容易造成数据积压，导致该单位的数据集成任务延迟"
        jb2_41 = {jb2_41: [nr01, nr02, nr03, nr04, nr05]}
        jb2_42 = "4.2\t云平台端"
        nr01 = "目前云平台运行基本稳定，存在的问题不是很多，本月出现错误的任务也不多并且问题的错误类型相对集中，大部分的错误都是由于运维操作的方式不规范及云平台扩容导致的任务出错。"
        nr02 = "上述的问题可以通过以下方法解决："
        nr03 = "（1）对于脏数据问题，需要当地运维人员严格按照云平台提供的运维规范对附加日志进行操作。"
        nr04 = "（2）平台原因导致的异常，例如实例调度失败、IO异常、安全策略不通等，有问题再联系阿里解决后再重跑即可。"
        jb2_42 = {jb2_42: [nr01, nr02, nr03, nr04]}
        # jb1_4={jb1_4:[jb2_41,jb2_42]}

        # 将所有的组成大字典，不用列表可以减少一层关系
        all_text = {
            jb1_1: [jb2_11, jb2_12, jb2_13],
            jb1_2: [jb2_21, jb2_22, jb2_23],
            jb1_3: [jb2_31, jb2_32],
            jb1_4: [jb2_41, jb2_42]
        }

        return nr21,all_text

    # if __name__ == '__main__':
    #     nr,all=hqnr()
    #     print(all)
